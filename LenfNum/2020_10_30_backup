using System;
using System.Collections.Concurrent;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Runtime.CompilerServices;
using System.Text;
using System.Threading.Tasks;
using Microsoft.ConcurrencyVisualizer.Instrumentation;
using Microsoft.ConcurrencyVisualizer;
using System.Windows.Forms;
using System.Runtime.InteropServices;
using System.Data.SqlClient;
using System.Threading;
using System.Data.Odbc;
using System.Xml;
using Lenf;
using System.Runtime.InteropServices.WindowsRuntime;

namespace LenfNum {
    public class LenfNum {
        #region Attribute
        private static Random r = new Random();
        private static double positiveLimit = 1e-8;
        private static double negitiveLimit = -1e-8;
        public short row, column;
        private double[][] _value;
        #endregion

        #region Setter Getter
        public double this[short r, short c] {
            get {
                return _value[r][c];
            }
            set {
                _value[r][c] = value < 0 ? (value < negitiveLimit ? value : negitiveLimit) : (value > positiveLimit ? value : positiveLimit);
            }
        }
        public double[] this[short r] {
            get {
                return _value[r];
            }
            set {
                var lenght = value.Length;
                _value[r] = new double[lenght];
                for(short i = 0; i < lenght; i++) {
                    this[r, i] = value[i];
                }
            }
        }
        #endregion

        #region Constructor
        public LenfNum(short _row, short _column, double OriginValue) {
            row = _row;
            column = _column;
            _value = new double[row][];
            for(short i = 0; i < row; i++) {
                this[i] = Enumerable.Repeat(OriginValue, column).ToArray();
            }
        }
        public LenfNum(short _row, short _column) {
            row = _row;
            column = _column;
            _value = new double[row][];
            for(short i = 0; i < row; i++) {
                this[i] = Enumerable.Repeat(0d, column).ToArray();
                for(short j = 0; j < column; j++) {
                    this[i, j] = (r.NextDouble() - 0.5) / 5d;
                }
            }
        }
        public LenfNum(double[] __value) {
            row = 1;
            column = (short)__value.Count();
            _value = Enumerable.Repeat(__value, 1).ToArray();
        }
        public LenfNum(double[][] __value) {
            row = (short)__value.Count();
            column = (short)__value.First().Count();
            _value = __value;
        }
        public LenfNum(short OneHotposition) {
            var a = Enumerable.Repeat(0d, 10).ToArray();
            a[OneHotposition] = 1;
            _value = Enumerable.Repeat(a, 1).ToArray();
        }
        #endregion

        #region Operator
        public static LenfNum operator +(LenfNum augend, LenfNum addend) {
            short row = augend.row;
            short column = augend.column;
            var d = new LenfNum(row, column);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i, j] = augend[i, j] + addend[i, j];
                }
            }
            return d;
        }
        public static LenfNum operator +(LenfNum augend, double addend) {
            short row = augend.row;
            short column = augend.column;
            var d = new LenfNum(row, column);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i, j] = augend[i, j] + addend;
                }
            }
            return d;
        }
        public static LenfNum operator -(LenfNum augend, LenfNum addend) {
            short row = augend.row;
            short column = augend.column;
            var d = new LenfNum(row, column);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i, j] = augend[i, j] - addend[i, j];
                }
            }
            return d;
        }
        public static LenfNum operator -(LenfNum augend, double addend) {
            short row = augend.row;
            short column = augend.column;
            var d = new LenfNum(row, column);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i, j] = augend[i, j] - addend;
                }
            }
            return d;
        }
        public static LenfNum operator *(LenfNum augend, LenfNum addend) {
            short row = augend.row;
            short column = augend.column;
            var d = new LenfNum(row, column);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i, j] = augend[i, j] * addend[i, j];
                }
            }
            return d;
        }
        public static LenfNum operator *(LenfNum augend, double addend) {
            short row = augend.row;
            short column = augend.column;
            var d = new LenfNum(row, column);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i, j] = augend[i, j] * addend;
                }
            }
            return d;
        }
        public static LenfNum operator /(LenfNum augend, LenfNum addend) {
            short row = augend.row;
            short column = augend.column;
            var d = new LenfNum(row, column);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i][j] = augend[i, j] / addend[i, j];
                }
            }
            return d;
        }
        public static LenfNum operator /(LenfNum augend, double addend) {
            short row = augend.row;
            short column = augend.column;
            var d = new LenfNum(row, column);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i, j] = augend[i, j] / addend;
                }
            }
            return d;
        }
        #endregion

        #region Overriding
        public override string ToString() {
            return String.Join("\r\n", _value.Select(x => String.Join(", ", x.Select(y => y))));
        }
        #endregion

        #region NormalFunction
        public int Count() {
            return row * column;
        }
        public double Sum() {
            var sum = 0d;
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    sum += this[i, j];
                }
            }
            return sum;
        }
        public double Min() {
            var m = double.PositiveInfinity;
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    m = this[i, j] < m ? this[i, j] : m;
                }
            }
            return m;
        }
        public double Max() {
            var m = double.NegativeInfinity;
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    m = this[i, j] > m ? this[i, j] : m;
                }
            }
            return m;
        }
        public LenfNum FuncToAll(Func<double, double> func) {
            var d = new LenfNum(row, column, 0d);
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    d[i, j] = func(this[i, j]);
                }
            }
            return d;
        }
        public LenfNum FuncForAll(Func<double, double> func) {
            for(short i = 0; i < row; i++) {
                for(short j = 0; j < column; j++) {
                    this[i, j] = func(this[i, j]);
                }
            }
            return this;
        }
        public List<List<double>> Alllist() {
            return _value.Select(x => x.Select(y => y).ToList()).ToList();
        }
        #endregion

        #region Matrix
        public LenfNum Transposed() {
            var sql = new LenfNum(column, row, 0d);
            for(short i = 0; i < column; i++) {
                for(short j = 0; j < row; j++) {
                    sql[i, j] = this[j, i];
                }
            }
            return sql;
        }
        public LenfNum Multiply(LenfNum Multier) {
            if(Multier == null)
                return this;
            if(column != Multier.row)
                throw new Exception("Can't multiply AAAAA");

            var c = row;
            var d = Multier.column;
            var e = column;
            var f = new LenfNum(c, d, 0d);

            for(short i = 0; i < c; i++) {
                for(short j = 0; j < d; j++) {
                    for(short k = 0; k < e; k++) {
                        f[i, j] += this[i, k] * Multier[k, j];
                    }
                }
            }

            return f;
        }
        #endregion
    }
    public abstract class Layer {
        public short Get, Give;
        public double LearningRate;
        public LenfNum Input, Partial;

        public Layer(short get, short give, double learningRate) {
            Get = get;
            Give = give;
            LearningRate = -learningRate;
        }

        protected abstract LenfNum CalculateOutput(LenfNum input);
        protected abstract LenfNum BackPropagation(LenfNum lastLayer);
        protected abstract void GradientDescent();
    }
    public class DenseLayer : Layer {
        public LenfNum Weight, Bias, BeforeActive, AfterActive;

        public Func<Layer, LenfNum>[] ActivityFunction/* = LenfNetworkFunction.ActivityFunction.Softmax*/;
        public DenseLayer(short get, short give, double learningRate = 0.5, Func<LenfLayer, LenfNum>[] activityFunction = null) : base(get, give, learningRate) {
            //ActivityFunction = activityFunction ?? ActivityFunction;
            Weight = new LenfNum(get, give);
            Bias = new LenfNum(1, give, 0);
        }

        protected override LenfNum CalculateOutput(LenfNum input) {
            Input = input;
            BeforeActive = input.Multiply(Weight) + Bias;
            AfterActive = ActivityFunction[0](this);
            return AfterActive;
        }
        protected override LenfNum BackPropagation(LenfNum lastLayer) {
            Partial = lastLayer * ActivityFunction[1](this);
            return Partial.Multiply(Weight.Transposed());
        }
        protected override void GradientDescent() {
            Weight += Input.Transposed().Multiply(Partial) * LearningRate;
            Bias += Partial * LearningRate / 10;
        }
    }
    public class LenfNormalizeLayer : Layer{
        public double Weight, Bias;
        public LenfNum BeforeNormal, AfterNormal;


        public Func<Layer, LenfNum>[] NormalizeFunction/* = LenfNetworkFunction.NormalizeFunction.BatchNormalize*/;
        public LenfNormalizeLayer(short get, short give, double learningRate = 0.5, Func<LenfLayer, LenfNum>[] normalizeFunction = null) : base(get, give, learningRate) {
            //ActivityFunction = activityFunction ?? ActivityFunction;
        }

        protected override LenfNum CalculateOutput(LenfNum input) {
            AfterNormal = NormalizeFunction[0](this);
            return AfterNormal * Weight + Bias;
        }
        protected override LenfNum BackPropagation(LenfNum lastLayer) {
            Partial = lastLayer;
            return NormalizeFunction[1](this) * Weight;
        }
        protected override void GradientDescent() {
            Weight += (Partial * AfterNormal * LearningRate).Sum();
            Bias += (Partial * LearningRate).Sum();
        }
    }
    public class LenfConvolutionLayer {

    }
    public class LenfLayer {
        public short Get, Give;
        public double LearningRate;
        public LenfNum Input, Weight, Bais, BeforeNormal, BeforeActive, AfterActive, Partial;

        public Func<LenfLayer, LenfNum>[] NormalizeFunction = LenfNetworkFunction.NormalizeFunction.BatchNormalize;
        public Func<LenfLayer, LenfNum>[] ActivityFunction = LenfNetworkFunction.ActivityFunction.Softmax;

        public LenfLayer(short get, short give, double learningRate = 0.05, Func<LenfLayer, LenfNum>[] activityFunction = null, Func<LenfLayer, LenfNum>[] normalizeFunction = null) {
            Get = get;
            Give = give;
            Weight = new LenfNum(get, give);
            Bais = new LenfNum(1, give, 0);
            LearningRate = -learningRate;
            NormalizeFunction = normalizeFunction ?? NormalizeFunction;
            //NormalizeFunction = null;
            ActivityFunction = activityFunction ?? ActivityFunction;
        }
        public LenfLayer(LenfNum partial,short get,short give) {
            Partial = partial;
            Get = get;
            Give = give;
            NormalizeFunction = null;
            ActivityFunction = null;
        }
        public LenfNum CalculateOutput(LenfNum input, bool islastLayer) {
            Input = input;
            BeforeNormal = (input.Multiply(Weight) + Bais);
            if(!islastLayer) {
                BeforeActive = NormalizeFunction[0](this);
            } else {
                BeforeActive = BeforeNormal;
            }
            AfterActive = ActivityFunction[0](this);
            return AfterActive;
        }
    }
    public class LenfNetwork {
        public List<LenfLayer> Layers = new List<LenfLayer>();

        public Func<LenfNum, LenfNum, LenfNum>[] CostFunction = LenfNetworkFunction.CostFunction.CrossEntropy;
        public LenfNetwork(List<LenfLayer> layers, Func<LenfNum, LenfNum, LenfNum>[] costFunction = null) {
            CostFunction = costFunction ?? CostFunction;

            if(!layers.Select(x => x.Get).Skip(1).Zip(layers.Select(x => x.Give).Take(layers.Count - 1), (x, y) => x == y).All(x => x))
                throw new Exception("Layer should be concat(?");

            Layers.AddRange(layers);
        }
        #region FunctionAddLayer
        //public void AddLayer(LenfLayer layer, short? firstInputCount = null) {
        //    layer.Input = Layers.Count == 0 ? new LenfNum(1, firstInputCount ?? throw new Exception("First Layer should have input size")) : new LenfNum(Layers.Last().give,layer.get);
        //    Layers.Add(layer);
        //}
        //public void AddRangeLayers(List<LenfLayer> layers, short? firstInputCount = null) {
        //    foreach(var layer in layers) {
        //        AddLayer(layer, firstInputCount);
        //    }
        //}
        #endregion
        public LenfNum Calculate(LenfNum CheckData) {
            var finalOutput = GetFinalOutput(CheckData);
            var totalCost = CostFunction[0](finalOutput * -1, CheckData).Sum();
            return finalOutput;
        }
        public double Train(LenfNum TrainData, LenfNum CheckData) {
            var finalOutput = GetFinalOutput(TrainData) * -1;
            var totalCost = -CostFunction[0](finalOutput * -1, CheckData).Sum();
            ReFreshPartial(new LenfLayer(CostFunction[1](finalOutput, CheckData),1,Layers.Last().Give),CheckData);
            return totalCost;
        }
        public LenfNum GetFinalOutput(LenfNum TrainData) {
            var lastlayer = Layers.Last();
            foreach(var layer in Layers) {
                TrainData = layer.CalculateOutput(TrainData, layer == lastlayer);
                //TrainData = layer.CalculateOutput(TrainData, false);
            }
            return TrainData;
        }
        public void ReFreshPartial(LenfLayer CostData, LenfNum CheckData) {
            foreach(var layer in Layers.ToArray().Reverse()) {
                layer.Partial = (CostData.Partial).Multiply(CostData.Weight?.Transposed() ?? null) *
                    (layer.ActivityFunction?[1].Invoke(layer) ?? new LenfNum(CostData.Get, CostData.Give, 1d)) *
                    (layer.NormalizeFunction?[1].Invoke(layer) ?? new LenfNum(CostData.Get, CostData.Give, 1d));
                if(layer == Layers.Last())
                    layer.Partial /= (layer.NormalizeFunction?[1].Invoke(layer) ?? new LenfNum(CostData.Get, CostData.Give, 1d));
                CostData = layer;
            }
            foreach(var layer in Layers) {
                layer.Bais += layer.Partial * layer.LearningRate / 10;
                layer.Weight += layer.Input.Transposed().Multiply(layer.Partial) * layer.LearningRate;
            }
        }
    }
    public static class LenfNetworkFunction {
        public static class ActivityFunction {
            public static Func<LenfLayer, LenfNum>[] Sigmoid = new Func<LenfLayer, LenfNum>[] {
                (x) => {
                    return x.BeforeActive.FuncToAll(x => 1 / (1 + Math.Exp(-x)));
                },
                (x) => {
                    return x.AfterActive.FuncToAll(x => x * (1 - x));
                }
            };

            public static Func<LenfLayer, LenfNum>[] Softmax = new Func<LenfLayer, LenfNum>[] {
                (x) => {
                    var total = x.BeforeActive.FuncToAll(x => Math.Exp(x)).Sum();
                    return x.BeforeActive.FuncToAll(x => Math.Exp(x) / total);
                },
                (x) => {
                    return x.AfterActive.FuncToAll(x => x - x * x);
                }
            };

            public static Func<LenfLayer, LenfNum>[] ReLU = new Func<LenfLayer, LenfNum>[] {
                (x) => {
                    return x.BeforeActive.FuncToAll(x => x > 0 ? x : -0.8 * x);
                },
                (x) => {
                    return x.AfterActive.FuncToAll(x => x > 0 ? 1 : -0.8);
                }
            };
        }
        public static class NormalizeFunction {
            public static Func<LenfLayer, LenfNum>[] MinMaxNormalize = new Func<LenfLayer, LenfNum>[] {
                (x) => {
                    var max = x.BeforeNormal.Max();
                    return x.BeforeNormal.FuncToAll(y => y / max);
                },
                (x) => {
                    var max = x.BeforeNormal.Max();
                    return x.BeforeNormal.FuncToAll(y => 1 / max);
                }
            };
            public static Func<LenfLayer, LenfNum>[] BatchNormalize = new Func<LenfLayer, LenfNum>[] {
                (x) => {
                    var mean = x.BeforeNormal.Sum() / x.BeforeNormal.Count();
                    var variance = Math.Sqrt(x.BeforeNormal.FuncToAll(x=>Math.Pow(x-mean,2)).Sum() / x.BeforeNormal.Count());
                    return x.BeforeNormal.FuncToAll(x => (x - mean) / (variance + 1e-8));
                },
                (x) => {
                    var mean = x.BeforeNormal.Sum() / x.BeforeNormal.Count();
                    var variance = Math.Sqrt(x.BeforeNormal.FuncToAll(x=>Math.Pow(x-mean,2)).Sum() / x.BeforeNormal.Count());
                    return (x.BeforeActive * x.BeforeActive + 1 - x.BeforeNormal.Count()) / x.BeforeNormal.Count() / -variance;
                }
            };
        }
        public static class CostFunction {
            public static Func<LenfNum, LenfNum, LenfNum>[] CrossEntropy = new Func<LenfNum, LenfNum, LenfNum>[] {
                (x, y) => {
                    var row = x.row;
                    var column = x.column;
                    var d = new LenfNum(row,column);
                    for(short i = 0; i < row; i++) {
                        for(short j = 0; j < column; j++) {
                            d[i][j] = Math.Log( y[i][j] == 0 ? ( 1 - x[i][j] ) : x[i][j] );
                        }
                    }
                    return d;
                },
                (x, y) => {
                    var row = x.row;
                    var column = x.column;
                    var d = new LenfNum(row,column);
                    for(short i = 0; i < row; i++) {
                        for(short j = 0; j < column; j++) {
                            d[i][j] = 1 / ( y[i][j] == 0 ? ( 1 - x[i][j] ) : x[i][j] );
                        }
                    }
                    return d;
                }
            };
        }
    }
}
